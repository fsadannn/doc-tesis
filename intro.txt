In many scientific and engineering applications, the dynamics of a system can be described by ordinary differential equations (ODEs). However, in certain cases, the ODEs can be "stiff," meaning that they involve vastly different time scales in the dynamics of the system. This can make traditional numerical integration methods very slow or even fail to converge.

Exponential integrators are a class of numerical methods used for solving stiff ODEs. These methods are based on the idea of using matrix exponential functions to approximate the solution of the ODE. Exponential integrators involve splitting the differential equation into two parts: a non-stiff part and a stiff part. The non-stiff part is integrated using a standard numerical method, while the stiff part is integrated using an exponential function. The key advantage of this approach is that the exponential function can be efficiently computed using techniques from linear algebra.

Exponential integrators have been found to be very efficient and accurate for a wide range of stiff ODEs, including those arising in chemical kinetics, fluid dynamics, and solid mechanics. They are particularly useful for problems where the stiffness varies over time, as they can adaptively switch between different numerical methods depending on the stiffness of the problem at any given time.

The goal of this thesis is to investigate the use of exponential integrators for solving stiff ODEs and to explore their performance for different types of problems. Specifically, we will focus on the use of different types of exponential integrators, such as the exponential Euler, exponential midpoint, and exponential Rosenbrock methods, and compare their accuracy and computational efficiency. We will also investigate the ability of exponential integrators to handle stiff ODEs with complex eigenvalue spectra and to adaptively handle varying stiffness in the system.

The results of this thesis will contribute to the understanding of the performance and applicability of exponential integrators for solving stiff ODEs. The insights gained from this research can be applied to a wide range of scientific and engineering problems involving stiff ODEs, and can help to improve the efficiency and accuracy of numerical simulations in these fields.


There are several techniques used to efficiently compute matrix exponentials. Here are a few examples:

    Krylov subspace methods: Krylov subspace methods are iterative techniques that use a sequence of powers of a matrix to approximate the matrix exponential. These methods are particularly effective for large sparse matrices and can be more efficient than direct methods for computing matrix exponentials.

    Padé approximations: Padé approximations are rational function approximations of the matrix exponential that can be computed using the coefficients of the Taylor series expansion of the exponential. These approximations can provide accurate results for a wide range of matrices and are often used in conjunction with Krylov subspace methods.

    Scaling and squaring methods: Scaling and squaring methods involve scaling the matrix by a factor and then computing the exponential of the scaled matrix using a Taylor series expansion or other approximation. The result is then raised to a power to obtain the original exponential. These methods can be used to compute the exponential of non-normal matrices, which can be challenging with other methods.

    Chebyshev polynomial methods: Chebyshev polynomial methods use Chebyshev polynomials to approximate the matrix exponential. These methods can be particularly effective for matrices with real eigenvalues and can be implemented using fast Fourier transforms.

    Lanczos methods: Lanczos methods are iterative methods that compute a sequence of Krylov vectors that can be used to approximate the matrix exponential. These methods are particularly effective for matrices with a small number of dominant eigenvalues and can be more efficient than other methods in these cases.

These methods can be used alone or in combination with each other to efficiently compute matrix exponentials for a wide range of matrices. The choice of the appropriate method depends on the specific problem being solved and the desired balance between accuracy and 

The accuracy and computational cost of the various techniques for computing matrix exponentials depend on several factors, such as the size and structure of the matrix, the desired level of accuracy, and the available computational resources. Here is a general comparison of the techniques in terms of their relative strengths and weaknesses:

    Krylov subspace methods: Krylov subspace methods are generally very efficient for large sparse matrices, as they only require matrix-vector multiplications and can be implemented using iterative algorithms. However, the accuracy of these methods can be affected by the choice of the starting vector and the number of Krylov vectors used, and may require additional techniques such as Padé approximations to improve accuracy.

    Padé approximations: Padé approximations can provide high accuracy for a wide range of matrices and are often used in conjunction with Krylov subspace methods. However, the computational cost of these methods can be higher than other techniques, particularly for large matrices or high orders of approximation.

    Scaling and squaring methods: Scaling and squaring methods can be very efficient for matrices with non-negative eigenvalues, as they can be implemented using simple operations such as matrix multiplication and exponentiation of scalars. However, the accuracy of these methods can be affected by the scaling factor used and the order of the approximation, and may require additional techniques such as Padé approximations to improve accuracy.

    Chebyshev polynomial methods: Chebyshev polynomial methods can provide high accuracy for matrices with real eigenvalues and can be implemented using fast Fourier transforms. However, the computational cost of these methods can be higher than other techniques, particularly for matrices with complex eigenvalues.

    Lanczos methods: Lanczos methods can be very efficient for matrices with a small number of dominant eigenvalues, as they only require matrix-vector multiplications and can be implemented using iterative algorithms. However, the accuracy of these methods can be affected by the number of Lanczos vectors used and may require additional techniques such as Padé approximations to improve accuracy.

Overall, the choice of the appropriate technique for computing matrix exponentials depends on the specific problem being solved and the desired balance between accuracy and computational cost. In practice, a combination of these techniques may be used to achieve high accuracy and efficiency for a wide range of matrices.